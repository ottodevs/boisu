// This is a manifest file that'll be compiled into application.js, which will include all the files
// listed below.
//
// Any JavaScript/Coffee file within this directory, lib/assets/javascripts, vendor/assets/javascripts,
// or any plugin's vendor/assets/javascripts directory can be referenced here using a relative path.
//
// It's not advisable to add code directly here, but if you do, it'll appear at the bottom of the
// compiled file. JavaScript code in this file should be added after the last require_* statement.
//
// Read Sprockets README (https://github.com/rails/sprockets#sprockets-directives) for details
// about supported directives.
//
// = require jquery
// = require bootstrap-sprockets
// = require jquery_ujs
// = require turbolinks
// = require_tree .

// fork getUserMedia for multiple browser versions, for the future
// when more browsers support MediaRecorder
navigator.getUserMedia = (navigator.getUserMedia ||
                     navigator.webkitGetUserMedia ||
                     navigator.mozGetUserMedia ||
                     navigator.msGetUserMedia)

// set up basic variables for app

var record = document.querySelector('.record')
var stop = document.querySelector('.stop')
var soundClips = document.querySelector('.sound-clips')
var canvas = document.querySelector('.visualizer')

// disable stop button while not recording

// stop.disabled = true;

// visualiser setup - create web audio api context and canvas

var audioCtx = new (window.AudioContext || webkitAudioContext)()
var canvasCtx = canvas.getContext('2d')

// main block for doing the audio recording

if (navigator.getUserMedia) {
  console.log('getUserMedia supported.')

  var constraints = { audio: true }
  var chunks = []

  var onSuccess = function (stream) {
    var mediaRecorder = new MediaRecorder(stream)

    visualize(stream)

    record.onclick = function () {
      // stop.disabled = false;
      // record.disabled = true;

      if ($('.record').hasClass('active')) {
        $('.visualizer').show()
        mediaRecorder.start()
        console.log(mediaRecorder.state)
        console.log('recorder started')
        // record.style.background = "red";
        // mediaRecorder.requestData();

        // stop.disabled = true;
        // record.disabled = false;
      } else {
        $('.visualizer').hide()
        mediaRecorder.stop()
        console.log(mediaRecorder.state)
        console.log('recorder stopped')
        // record.style.background = "";
        // record.style.color = "";
      }
    }

    // stop.onclick = function() {
    //   $('.visualizer').hide();
    //   mediaRecorder.stop();
    //   console.log(mediaRecorder.state);
    //   console.log("recorder stopped");
    //   record.style.background = "";
    //   record.style.color = "";
    //   // mediaRecorder.requestData();
    //
    //   stop.disabled = true;
    //   record.disabled = false;
    // }

    mediaRecorder.onstop = function (e) {
      console.log('data available after MediaRecorder.stop() called.')

      // var clipName = prompt('Enter a name for your sound clip?','My unnamed clip');
      // console.log(clipName);
      var clipContainer = document.createElement('article')
      var clipLabel = document.createElement('p')
      var audio = document.createElement('audio')
      var deleteButton = document.createElement('button')

      clipContainer.classList.add('clip')
      audio.setAttribute('controls', '')
      deleteButton.textContent = 'Delete'
      deleteButton.className = 'delete'

      // if(clipName === null) {
      //   clipLabel.textContent = 'My unnamed clip';
      // } else {
      //   clipLabel.textContent = clipName;
      // }

      clipContainer.appendChild(audio)
      clipContainer.appendChild(clipLabel)
      clipContainer.appendChild(deleteButton)
      soundClips.appendChild(clipContainer)

      audio.controls = true
      var blob = new Blob(chunks, { 'type': 'audio/ogg; codecs=opus' })
      // var blob = new Blob(chunks, { 'type' : 'audio/wav' });

      chunks = []
      var audioURL = window.URL.createObjectURL(blob)
      audio.src = audioURL
      console.log('recorder stopped')

      deleteButton.onclick = function (e) {
        evtTgt = e.target
        evtTgt.parentNode.parentNode.removeChild(evtTgt.parentNode)
      }
      var formdata = new FormData()
      formdata.append('voice_message[audio]', blob)
      $.ajax({
        type: 'POST',
        url: '/voice_messages',
        data: formdata,
        processData: false,
        contentType: false
      })

      // clipLabel.onclick = function() {
      //   var existingName = clipLabel.textContent;
      //   var newClipName = prompt('Enter a new name for your sound clip?');
      //   if(newClipName === null) {
      //     clipLabel.textContent = existingName;
      //   } else {
      //     clipLabel.textContent = newClipName;
      //   }
      // }
    }

    mediaRecorder.ondataavailable = function (e) {
      chunks.push(e.data)
    }
  }

  var onError = function (err) {
    console.log('The following error occured: ' + err)
  }

  navigator.getUserMedia(constraints, onSuccess, onError)
} else {
  console.log('getUserMedia not supported on your browser!')
}

function visualize (stream) {
  var source = audioCtx.createMediaStreamSource(stream)

  var analyser = audioCtx.createAnalyser()
  analyser.fftSize = 2048
  var bufferLength = analyser.frequencyBinCount
  var dataArray = new Uint8Array(bufferLength)

  source.connect(analyser)
    // analyser.connect(audioCtx.destination);

  WIDTH = canvas.width
  HEIGHT = canvas.height

  draw()

  function draw () {
    requestAnimationFrame(draw)

    analyser.getByteTimeDomainData(dataArray)

    canvasCtx.fillStyle = 'rgb(200, 200, 200)'
    canvasCtx.fillRect(0, 0, WIDTH, HEIGHT)

    canvasCtx.lineWidth = 2
    canvasCtx.strokeStyle = 'rgb(0, 0, 0)'

    canvasCtx.beginPath()

    var sliceWidth = WIDTH * 1.0 / bufferLength
    var x = 0

    for (var i = 0; i < bufferLength; i++) {
      var v = dataArray[i] / 128.0
      var y = v * HEIGHT / 2

      if (i === 0) {
        canvasCtx.moveTo(x, y)
      } else {
        canvasCtx.lineTo(x, y)
      }

      x += sliceWidth
    }

    canvasCtx.lineTo(canvas.width, canvas.height / 2)
    canvasCtx.stroke()
  }
}

// Navigation drawer
$(document).ready(function () {
  $('.button').click(function () {
    $(this).toggleClass('active')
  })

  burger()

 // Navigation Menu Slider
  $('#nav-expander').on('click', function (e) {
    e.preventDefault()
    $('body').toggleClass('nav-expanded')
  })
  $('#nav-close').on('click', function (e) {
    e.preventDefault()
    $('body').removeClass('nav-expanded')
  })

  // Initialize navgoco with default options
  // $(".main-menu").navgoco({
  //     caret: '<span class="caret"></span>',
  //     accordion: false,
  //     openClass: 'open',
  //     save: true,
  //     cookie: {
  //         name: 'navgoco',
  //         expires: false,
  //         path: '/'
  //     },
  //     slide: {
  //         duration: 300,
  //         easing: 'swing'
  //     }
  // });
})

// burger
function burger () {
  var control = $('svg')
  var lines = $('line')

  control.on('click', function () {
    if (lines.attr('type') == 'burger') {
      lines.attr('type', 'close')
    } else {
      lines.attr('type', 'burger')
    }
  })
}
